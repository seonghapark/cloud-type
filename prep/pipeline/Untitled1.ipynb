{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.5.0 and strictly below 2.8.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "import numpy  as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "def data_extractor_fn(filelist,prefetch=1, read_threads=4, distribute=(1, 0), nlimit = 100):\n",
    "    def parser(ser):\n",
    "        \"\"\"\n",
    "        Decode & Pass datast in tf.record\n",
    "        *Cuation*\n",
    "        floating point: tfrecord data ==> tf.float64\n",
    "        \"\"\"\n",
    "        features = {\n",
    "            \"shape\": tf.io.FixedLenFeature([3], tf.int64),\n",
    "            \"patch\": tf.io.FixedLenFeature([], tf.string),\n",
    "            \"filename\": tf.io.FixedLenFeature([], tf.string),\n",
    "            \"coordinate\": tf.io.FixedLenFeature([2], tf.int64),\n",
    "        }\n",
    "        decoded = tf.io.parse_single_example(ser, features)\n",
    "        patch = tf.reshape(\n",
    "            tf.io.decode_raw(decoded[\"patch\"], tf.float64), decoded[\"shape\"]\n",
    "        )\n",
    "        # keep the value as float64\n",
    "\n",
    "        # get other configs\n",
    "        filename = decoded[\"filename\"]\n",
    "        coordinate = decoded[\"coordinate\"]\n",
    "        return patch, filename, coordinate\n",
    "    \n",
    "    dataset = (\n",
    "        tf.data.Dataset.list_files(filelist, shuffle=True)\n",
    "            .shard(*distribute)\n",
    "            .apply(\n",
    "            tf.data.experimental.parallel_interleave(\n",
    "                lambda f: tf.data.TFRecordDataset(f).map(parser),\n",
    "                cycle_length=read_threads,\n",
    "                sloppy=True,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # iterator = dataset.make_one_shot_iterator()\n",
    "    iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "    next_element = iterator.get_next()\n",
    "    \n",
    "    # Process\n",
    "    idx = 0\n",
    "    patches = None\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        try:\n",
    "            while True:\n",
    "                patch, filename, coord  = sess.run(next_element)\n",
    "                #yield  patch, filename.decode(\"utf-8\"), coord\n",
    "                _patch = np.expand_dims(patch, axis=0)\n",
    "                if idx == 0:\n",
    "                    patches = _patch\n",
    "                else:\n",
    "                    patches = np.concatenate([patches, _patch], axis=0)\n",
    "                idx+=1\n",
    "                \n",
    "                if idx >= nlimit:\n",
    "                    break\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            #if crank == 0:\n",
    "            print(\" ###  TF-DEOCDED END--> next process ###\", flush=True)\n",
    "            pass\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_basedir=\"/tf/cloud-type/prep/pipeline\"\n",
    "tf_datadir=os.path.join(tf_basedir, 'out') # validation data\n",
    "filelist  = glob.glob(os.path.join(tf_datadir, '*.tfrecord'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tf/cloud-type/prep/pipeline/out/sample_0-3.tfrecord',\n",
       " '/tf/cloud-type/prep/pipeline/out/sample_0-4.tfrecord']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-18aace37f509>:30: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n"
     ]
    }
   ],
   "source": [
    "patches = data_extractor_fn(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 128, 128, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_model(model_dir, mtype):\n",
    "    #TODO add restart model dir and restart argument?\n",
    "    latest = 0, None\n",
    "    # get trained wegiht \n",
    "    for m in os.listdir(model_dir):\n",
    "        if \".h5\" in m and mtype in m:\n",
    "            epoch = int(m.split(\"-\")[1].replace(\".h5\", \"\"))\n",
    "            latest = max(latest, (epoch, m))\n",
    "\n",
    "    epoch, model_file = latest\n",
    "\n",
    "    if not os.listdir(model_dir):\n",
    "        raise NameError(\"no directory. check model path again\")\n",
    "\n",
    "    print(\" Load {} at {} epoch\".format(mtype, epoch))\n",
    "    model_def = model_dir+'/'+mtype+'.json'\n",
    "    model_weight = model_dir+'/'+mtype+'-'+str(epoch)+'.h5'\n",
    "    with open(model_def, \"r\") as f:\n",
    "        model = tf.keras.models.model_from_json(f.read())\n",
    "    model.load_weights(model_weight)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Load encoder at 200 epoch\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/layers/core/lambda_layer.py:303: UserWarning: models_update is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  function = cls._parse_function_from_config(config, custom_objects,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Load decoder at 200 epoch\n"
     ]
    }
   ],
   "source": [
    "model_datadir = '/tf/cloud-type/prep/pipeline'\n",
    "expname =  10057054 # 10056527\n",
    "model_dir = os.path.join(model_datadir,str(expname) )\n",
    "encoder = load_latest_model(model_dir, mtype='encoder')\n",
    "decoder = load_latest_model(model_dir, mtype='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = decoder\n",
    "\n",
    "### processing ###\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "encs = encoder.predict(patches)\n",
    "\n",
    "hello = tf.keras.Model(inputs=model.input, outputs=model.get_layer('conv2d_18').output)\n",
    "decoder_result = hello.predict(encs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8, 8, 128)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 128, 128, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
